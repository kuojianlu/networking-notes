# 计算机网络自顶向下方法

## 第1章 计算机网络和因特网

### 1.1 什么是因特网

#### 1.1.1 具体构成描述

- 主机/端系统、通信链路、分组交换机（包括路由器和链路层交换机两类）

### 1.3 网络核心

#### 1.3.1 分组交换

- 存储转发传输
  - 大多数分组交换机在链路的输入端使用存储转发传输机制。存储转发机制是指交换机能够开始向输出链路传输该分组的第一个比特之前，必须接收到整个分组
  - 由N条速率均为R的链路组成的链路（在源和目的地之间有N - 1台路由器），从源到目的地发送一个L比特分组，端到端时延是：$d=N\frac{L}{R}$

- 排队时延和分组丢失
- 转发表和路由选择协议

#### 1.3.2 电路交换

- 通过网络链路和交换机移动数据有两种基本方法：电路交换和分组交换

- 在电路交换网络中，在端系统间通信会话期间，预留了端系统间通信沿路径所需要的资源（缓存、链路传输速率）。在分组交换网络中，这些资源不是预留的：会话的报文按需使用这些资源，其后果可能是不得不等待（即排队）接入通信线路

- 电路交换网络中的复用

  - 链路中的电路是通过频分复用（Frequency-Division Multiplexing，FDM）或时分复用（Time-Division Multiplexing，TDM）来实现的

  - 对于FDM，链路的频谱由跨越链路创建的所有连接所共享。特别是，在连接期间为每条连接专用一个频段

  - 对于TDM，时间被划分为固定区间的帧，并且每帧又被划分为固定数量的时隙。当网络跨越一条链路创建一条连接时，网络在每个帧中为该链接指定一个时隙。这些时隙专门由该连接单独使用，一个时隙可用于传输该连接的数据

  - FMD和TMD的一个例子

    <img src="images/FMD和TMD的一个例子.png" alt="image-20200217141418099" style="zoom:50%;" />

### 1.4 分组交换网中的时延、丢包和吞吐量

#### 1.4.1 分组交换网中的时延概述

- 路由器A的节点时延

  <img src="images/路由器A的节点时延.png" alt="image-20200217151859715" style="zoom:50%;" />

  - 当分组从上游节点到达路由器A时，路由器A检查该分组的首部以决定该分组的适当处链路，并将该分组导向该链路
  - 仅当在该链路没有其他分组正在传输并且没有其他分组排在该队列的前面时，才能在这条链路上传输该分组；如果该链路当前正繁忙或有其他分组已经在该链路上排队，则新到达的分组则将参与排队

- 时延的类型
  - 处理时延（$d_{proc}$）：检查分组首部和决定将该分组导向何处所需要的时间是处理时延的一部分。处理时延也能包括其他因素，如检查比特级别的差错所需要的时间
  - 排队时延（$d_{queue}$）：在队列中，当分组在链路上等待传输时，它经受排队时延
  - 传输时延（$d_{trans}$）：用L比特表示该分组的长度，用R bps表示从路由器A到路由器B的链路传输速率，传输时延是L/R。这是将所有分组的比特推（传输）向链路所需要的时间。传输时延是路由器将分组推出所需要的时间，它是分组长度和链路传输速率的函数，而与两台路由器之间的距离无关
  - 传播时延（$d_{prop}$）：一个比特从一台路由器向另一台路由器传播所需要的时间，它是两台路由器之间距离的函数，与分组长度或链路传输速率无关

#### 1.4.2 排队时延和丢包

- 排队时延对每个分组可能是不同的，因此，当表征排队时延时，人们通常使用统计量测度，如平均排队时延、排队时延的方差和排队时延超过某些特定值的概率

- 排队时延取决于到达该队列的速率、链路的传输速率和到达流量的性质，即流量是周期性到达还是以突发形式到达

- 令a表示分组到达队列的平均速率（单位是分组/秒，即pkt/s）。则比特到达队列的平均速率是La bps。假定该队列无限大。比率La/R被称为流量强度，它在估计排队时延的范围方面经常起着重要的作用

  - 如果La/R > 1，则比特到达队列的平均速率超过从该队列传输出去的速率。在这种不幸的情况下，该队列趋向于无限增加，并且排队时延将趋向无穷大

  - La/R <= 1时，这时，到达流量的性质影响排队时延。如果分组周期性到达，即每L/R秒到达一个分组，则每个分组到达一个空队列中，不会有排队时延。在另一方面，如果分组以突发形式到达而不是周期性到达，则有很大的平均排队时延。例如，假定每(L/R)N秒同时到达N个分组，则传输的第一个分组没有排队时延；传输第n个分组具有(n-1)L/R秒的排队时延

  - 平均排队时延与流量强度的定性关系如图所示

    <img src="images/平均排队时延与流量强度的定性关系.png" alt="image-20200217154610789" style="zoom:50%;" />

    该图的一个重要方面是这样一个事实：随着流量强度接近于1，平均排队时延迅速增加。该强度少量的增加将导致时延大得多的增加

- 丢包
  
  - 在现实中，因为队列容量是有限的，随着流量强度接近1，排队时延并不实际趋向无穷大。相反，到达的分组将发现一个满的队列。由于没有地方存储这个分组，路由器将丢弃该分组，该分组将会丢失

### 1.5 协议层次及其服务模型

#### 1.5.1 分层的体系结构

- 因特网协议栈和OSI参考模型

  <img src="images/因特网协议栈和OSI参考模型.png" alt="image-20200217162556184" style="zoom:45%;" />

## 第3章 运输层

### 3.4 可靠数据传输原理

- 可靠数据传输机制及其用途的总结

  ![image-20200216232311158](images/可靠数据传输机制及其用途的总结.png)

#### 3.4.3 回退N步

- 在回退N步（Go-Back-N，GBN）协议中，允许发送方发送多个分组而不需等待确认，但它也受限于在流水线中未确认的分组数不能超过某个最大允许数N

- 在GBN中发送方看到的序号

  <img src="images/在GBN中发送方看到的序号.png" alt="image-20200216224850549" style="zoom:50%;" />

- N常被称为窗口长度，GBN协议也常被称为滑动窗口协议
- 为什么要限制这些被发送的、未被确认的分组的数目为N呢？
  - 流量控制是对发送发施加限制的原因之一
  - 拥塞控制是另一个原因

- GBN发送方必须响应三种类型的事件
  - 上层的调用：发送方受限检查发送窗口是否已满，若窗口未满，则产生一个分组并将其发送，并相应地更新变量；若窗口已满，发送方只需将数据返回给上层，隐式地指示上层该窗口已满。在实现中，发送方更可能缓存这些数据，或者使用同步机制允许上层在仅当窗口不满时才进行调用
  - 收到一个ACK：在GBN中，对序号为n的分组的确认采取累积确认的方式，表明接收方已正确接收到序号为n的以前且包括n在内的所有分组
  - 超时事件：如果出现超时，发送方重传所有已发送但还未被确认过的分组。发送方仅使用一个定时器，它可被当作是最早的已发送但未被确认的分组所使用的定时器。如果收到一个ACK，但仍有已发送但未被确认的分组，则定时器被重新启动。如果没有已发送但未被确认的分组，该定时器被终止

- GBN接收方的动作
  
  - 如果一个序号为n的分组被正确接收到，并且按序，则接收方为分组n发送一个ACK，并将该分组中的数据部分交付到上层。在所有其他情况下，接收方丢弃该分组，并为最近按序接收的分组重新发送ACK

#### 3.4.4 选择重传

- 选择重传（Selective Repeat，SR）协议通过让发送方仅重传那些它怀疑在接收方出错的分组而避免了不必要的重传。这种个别的、按需的重传要求接收方逐个地确认正确接收的分组

- 在SR中发送方与接收方看到的序号

  <img src="images/在SR中发送方与接收方看到的序号.png" alt="image-20200216230823564" style="zoom:50%;" />

- SR发送方所采取的动作
  - 从上层接收到数据：同GBN
  - 超时：每个分组必须拥有自己的逻辑定时器，因为超时发生后只能发送一个分组
  - 收到ACK：若该分组序号在窗口内，则SR发送方将那个被确认的分组标记为已接收。如果该分组的序号等于send_base，则窗口基序号向前移动到具有最小序号的未被确认分组处。如果窗口移动了并且有序号落在窗口内的为发送分组，则发送这些分组

- SR接收方所采取的动作
  - 序号在[rcv_base，rcv_base + N - 1]内的分组被正确接收：一个选择ACK被回送给对方。如果该分组以前没收到过，则缓存该分组。如果该分组的序号等于接收窗口的基序号（rcv_base），则该分组以及以前缓存的序号连续的分组交付给上层。然后，接收窗口按向前移动分组的编号向上交付这些分组
  - 序号在[rcv_base - N，rcv_base - 1]内的分组被正确收到：在此情况下，必须产生一个ACK，即使该分组是接收方以前已确认过的分组
  - 其他情况：忽略该分组

- 对SR协议而言，发送方和接收方的窗口并不总是一致

### 3.5 面向连接的运输：TCP

- 差错检验、重传、累积确认、定时器、序号和确认号

#### 3.5.3 往返时间的估计与超时

- 估计往返时间
  - 报文段的样本RTT（SampleRTT）就是从某报文段被发出到对该报文段的确认被收到之间的时间量。大多数TCP的实现仅在某个时刻做一次SampleRTT测量，而不是为每个发送的报文段测量一个SampleRTT
  - 为了估计一个典型的RTT，TCP维持一个SampleRTT均值（称为EstimatedRTT）。一旦获得一个新SampleRTT时，TCP就会根据下列公式来更新EstimatedRTT：$EstimatedRTT=(1-\alpha)·EstimatedRTT+\alpha·SampleRTT$。在RFC 6298中给出的$\alpha$参考值是0.125
  - 值得注意的是，EstimatedRTT是一个SampleRTT值的加权平均值。这个加权平均对最近的样本赋予的权值要大于对老样本赋予的全值。这是很自然的，因为越近的样本越能更好地反映网络的当前拥塞情况。从统计学观点讲，这种平均被称为指数加权移动平均（Exponential Weighted Moving Average，EWMA）
  - 除了估算RTT外，测量RTT的变化也是有价值的。RFC 2698定义了RTT偏差DevRTT，用于估算SampleRTT一般会偏离EstimatedRTT的程度：$$DevRTT=(1-\beta)·DevRTT+\beta·|SampleRTT-EstimatedRTT|$$。注意到DevRTT是一个SampleRTT与Estimated之间差值的EWMA。如果SampleRTT值波动较小，那么DevRTT的值就会很小；另一方面，如果波动很大，那么DevRTT的值就会很。$\beta$的推荐值为0.25

- 设置和管理重传超时间隔
  - 假设已经给出了EstimatedRTT值和DevRTT值，那么很明显，超时间隔应该大于等于EstimatedRTT。但是超时间隔也不应该比EstimatedRTT大太多。因此要求将超时间隔设为EstimatedRTT加上一定余量。当SampleRTT值波动较大时，这个余量应该大些；当波动较小时，这个余量应该小些。因此，DevRTT值在这里发挥作用了：$$TimeoutInterval=EstimatedRTT+4·DevRTT$$。推荐的初始TimeoutInterval值为1秒（RFC 6298）。同样，当出现超时后，TimeoutInterval值将加倍，以免即将被确认的后继报文段过早出现超时。不管怎样，一旦报文段收到并更新EstimatedRTT后，TimeoutInterval就又使用上述公式计算了

#### 3.5.4 可靠的数据传输

- 在研发可靠数据传输技术时，曾假定每一个已发送但未被确认的报文段都与一个定时器相关联，虽然这在理论上很好，但定时器的管理却需要相当大的开销。因此，推荐的定时器管理过程（RFC 6298）仅使用单一的重传定时器，即使有多个已发送但还未被确认的报文段
- 一个TCP发送方的高度简化的描述，该发送方只用超时来恢复报文段的丢失
  - 从上层应用程序接收数据：TCP从应用程序接收数据，将数据封装在一个报文段中，并把该报文段交给IP。如果定时器还没有为某些其他报文段而运行，则当报文段被传给IP时，TCP就启动该定时器。该定时器的过期间隔是TimeoutInterval，由EstimatedRTT和DevRTT计算得出
  - 超时：TCP通过重传引起超时的报文段来响应超时事件。然后TCP重启定时器
  - 来自接收方的ACK：TCP将ACK的值y与它的变量SendBase进行比较。TCP采用累积确认，所以y确认了字节编号在y之前的所有字节都已经收到。如果y大于SendBase，则该ACK是在确认一个或多个先前未被确认的报文段。因此发送方更新它的SendBase变量；如果当前还有未被确认的报文段，TCP还要重新启动定时器
- 超时间隔加倍
  - TCP重传具有最小序号的还未被确认的报文段，只是每次TCP重传时都会将下一次的超时间隔设为先前值的两倍，而不是从EstimatedRTT和DevRTT推算出的值
  - 例如，假设当定时器第一次过期时，与最早的未被确认的报文段相关联的TimeoutInterval是0.75s，TCP就会重传该报文段，并把新的过期时间设置为1.5s。如果1.5s后定时器又过期了，则TCP将再次重传该报文段，并把过期时间设置为3.0s。因此，超时间隔在每次重传后回呈指数型增长。然而，每当定时器在另两个事件（即收到上层应用的数据和收到ACK）中的任意一个启动时，TimeoutInterval由最近的EstimatedRTT和DevRTT推算得到
  - 这种修改提供了一个形式受限的拥塞控制。定时器过期很可能是由网络拥塞引起的，即太多的分组到达源与目的地之间路径上的一台（或多台）路由器的队列中，造成分组丢失或长时间的排队时延。在拥塞的时候，如果源持续重传分组，会使拥塞更加严重。相反，TCP使用更文雅的方式，每个发送方的重传都是经过越来越长的时间间隔后进行的

- 快速重传

  - 超时触发重传存在的问题之一是超时周期可能相对较长。当一个报文段丢失时，这种长超时周期迫使发送方延迟重传丢失的分组，因而增加了端到端时延。幸运的是，发送方通常可在超时时间发生之前通过注意所谓冗余ACK来较好地检测到丢包情况

  - TCP接收方的ACK生成策略

    <img src="images/TCP接收方的ACK生成策略.png" alt="image-20200216223544854" style="zoom:50%;" />

  - 因为发送方经常一个接一个地发送大量的报文段，如果一个报文段丢失，就很可能引起许多一个接一个的冗余ACK。如果TCP发送方接收到对相同数据的3个冗余ACK，它把这当作一种暗示，说明跟在这个已被确认过3次的报文段之后的报文段已经丢失。一旦收到3个冗余ACK，TCP就执行快速重传，即在该报文段的定时器过期之前重传丢失的报文段

- 是回退N步还是选择重传
  - TCP更像一个GBN风格的协议，但和GBN有一些显著的区别
    - 许多TCP实现会将正确接收但失序的报文段缓存起来
    - GBN不仅会重传超时分组，还会重传所有后继的分组；而TCP只重传超时分组
  - RFC 2018对TCP提出一种修改意见是所谓的选择确认（selective acknowledgement），它允许TCP接收方有选择地确认失序报文段，而不是累积地确认最后一个正确接收的有序报文段。因此，TCP的差错恢复机制也许最好被分类为GBN和SR的混合体

#### 3.5.5 流量控制

- TCP为它的应用程序提供了流量控制服务，以消除发送方使接收方缓存溢出的可能性。流量控制因此是一个速度匹配服务，即发送方的发送速率与接收方应用程序的读取速率相匹配

- TCP通过让发送方维护一个称为接收窗口的变量来提供流量控制

- 假设主机A通过一条TCP连接向主机B发送一个大文件。定义以下变量

  - LastByteRead：主机B上的应用进程从缓存读出的数据流的最后一个字节的编号
  - LastByteRcvd：从网络中到达的并且已放入主机B接收缓存中的数据流的最后一个字节编号
  - rwnd：接收窗口

  由于TCP不允许已分配的缓存溢出，下式必须成立：$LastByteRcvd-LastByteRead\le RcvBuffer$。并且，$rwnd=RcvBuffer-(LastByteRcvd-LastByteRead)$。开始时，主机B设定$rwnd=RcvBuffer$

  主机A在该连接的整个生命周期必须保证：$LastByteSent-LastByteAcked\le rwnd$

- 这个方案还存在一个问题：假设主机B的接收缓存已经存满，使得rwnd = 0。在将rwnd = 0通告给主机A之后，假设主机B没有任何数据要发给主机A。此时，在主机B的应用进程将缓存清空后，TCP并不向主机A发送带有rwnd新值的报文段，因为事实上，TCP仅当它在有数据或有确认要发时才会发送报文段给主机A。这样，主机A不可能知道主机B的接收缓存已经有新的空间了，即主机A被阻塞而不能再发送数据

- 为了解决这个问题，TCP规范中要求：当主机B的接收窗口为0时，主机A继续发送只有一个字节数据的报文段。这些报文段将会被接收方确认。最终缓存将开始清空，并且确认报文里将包含一个非0的rwnd值

#### 3.5.6 TCP连接管理

- SYN洪泛攻击
  - 在TCP三次握手中，服务器为了响应一个收到的SYN，分配并初始化连接变量和缓存。然后服务器发送一个SYNACK进行响应，并等待来自客户的ACK。如果某客户不发送ACK来完成该三次握手，最终（通常在一分多钟之后）服务器将终止该半开连接并回收资源
  - 这种TCP连接管理协议为经典的Dos攻击即SYN洪泛攻击（SYN flood attack）提供了环境
  - 现在有一种有效的防御系统，称为SYN cookie，它们被部署在大多数主流操作系统中。SYN cookie以下列方式工作：
    - 当服务器接收到一个SYN报文段时，不会为该报文段生成一个半开连接，相反，服务器生存一个初始TCP序列号，该序列号是SYN报文段的源和目的地址与端口号，以及仅有该服务器知道的秘密数的一个复杂函数（散列函数）。这种精心制作的初始序列号被称为cookie。服务器则发送具有这种特殊初始序列号的SYNACK分组。重要的是，服务器并不记忆该cookie或任何对应于SYN的其他状态信息
    - 当服务器收到客户的ACK后，服务器将使用在ACK报文段中的源和目的IP地址与端口号以及秘密数运行相同的散列函数，如果该函数的结果加1与在客户的ACK的确认值相同的话，服务器将认为该ACK对应于较早开始的SYN报文段，因此它是合法的，服务器则生产一个具有套接字的全开的连接
    - 另一方面，如果客户没有返回一个ACK，则初始的SYN并没有对服务器产生危害，因为服务器没有为它分配任何资源

### 3.6 拥塞控制原理

#### 3.6.1 拥塞原因与代价

- 当分组的到达速率接近链路容量时，分组经历巨大的排队时延
- 发送方必须执行重传以补偿因为缓存溢出而丢失的分组
- 发送方在遇到大时延时所进行的不必要重传会引起路由器利用其链路带宽来转发不必要的分组副本
- 当一个分组沿一条路径被丢弃时，每个上游路由器用于转发该分组到丢弃该分组而使用的传输容量最终被浪费掉了

#### 3.6.2 拥塞控制方法

- 端到端拥塞控制
  - 在端到端拥塞控制方法中，网络层没有为运输层拥塞控制提供显式支持。即使网络中存在拥塞，端系统也必须通过对网络行为的观察（如分组丢失与时延）来推断之

- 网络辅助的拥塞控制
  - 在网络辅助的拥塞控制中，网络层构件（即路由器）向发送方提供关于网络中拥塞状态的显式反馈信息。这种反馈可以简单地用一个比特来指示链路中的拥塞情况
  - 拥塞信息从网络反馈到发送方通常有两种方式
    - 直接反馈信息可以由网络路由器发给发送方
    - 路由器标记或更新从发送方流向接收方的分组中的某个字段来指示拥塞的产生。一旦收到一个标记的分组后，接收方就会向发送方通知该网络拥塞指示

#### 3.6.3 网络辅助的拥塞控制例子：ATM ABR拥塞控制

### 3.7 TCP拥塞控制

- TCP必须使用端到端拥塞控制，因为IP层不向端系统提供显式的网络拥塞反馈
- TCP所采用的方法是让每一个发送方根据所感知到的网络拥塞程度来限制其能向连接发送流量的速率。如果一个TCP发送方感知从它到目的地直接的路径上没什么拥塞，则TCP发送方增加其发送速率；如果发送方感知沿着该路径有拥塞，则发送方就会降低其发送速率

- TCP发送方如何限制其向其连接发送流量的
  - 运行在发送方的TCP拥塞控制机制跟踪一个额外的变量，即拥塞窗口（congestion window），表示为cwnd，它对一个TCP发送方能向网络中发送流量的速率进行了限制。特别是，在一个发送方中未被确认的数量不会超过cwnd和rwnd中的最小值，即：$$LastByteSent-LastByteAcked\le min(cwnd, rwnd)$$

- 发送方如何感知在它与目的地之间的路径上出现了拥塞的
  - 将一个TCP发送方的“丢包事件”定义为：要么出现超时，要么收到来自接收方的3个冗余ACK。当出现过度拥塞时，在沿着这条路径上的一台（或多台）路由器的缓存会溢出，引起一个数据报被丢弃。丢弃的数据报接着会引起发送方的丢包事件，发送方就认为在发送方到接收方的路径上出现了拥塞的指示

- TCP发送方怎样确定它应当发送的速率，既使得网络不会拥塞，与此同时又能充分利用所有可用的带宽
  - TCP使用下列指导性原则
    - 一个丢失的报文段意味着拥塞，因此当丢失报文段时应当降低TCP发送方的速率
    - 一个确认报文段指示该网络正在向接收方交付发送方的报文段，因此，当对先前未确认的报文段的确认到达时，能够增加发送方的速率
    - 带宽探测：为探测拥塞开始出现的速率，TCP发送方增加它的传输速率，从该速率后退，进而再次开始探测，看看拥塞开始速率是否发生了变化

- TCP拥塞控制算法包括3个主要部分：慢启动、拥塞避免、快速恢复。慢启动和拥塞避免是TCP的强制部分，两者的差异在于对收到ACK做出反应时增加cwnd长度的方式，慢启动比拥塞避免能更快地增加cwnd的长度

- 慢启动
  - 当一条TCP开始时，cwnd的值通常初始置为一个MSS的较小值，这就使得初始发送速率大约为MSS/RTT
  - 在慢启动状态，cwnd的值以一个MSS开始，并且每当传输的报文段首次被确认就增加1个MSS。因此，TCP发送速率起始慢，但在慢启动阶段以指数增长
  - 何时结束这种指数增长
    - 如果存在一个由超时指示的丢包事件（即拥塞），TCP发送方将cwnd设置为1并重新开始慢启动过程。它还将第二个状态变量ssthresh（慢启动阈值）设置为cwnd/2，即当检测到拥塞时将ssthresh置为拥塞窗口值的一半
    - 慢启动结束的第二种方式是直接与ssthresh的值相关联。当cwnd的值等于ssthresh时，结束慢启动并且TCP转移到拥塞避免模式。当进入到拥塞避免模式时，TCP更为谨慎地增加cwnd
    - 最后一种结束慢启动的方式是，如果检测到3个冗余ACK，这时TCP执行一种快速重传并进入快速恢复状态

- 拥塞避免
  - 一旦进入拥塞避免状态，每个RTT只将cwnd的值增加一个MSS，这能够以几种方式完成
    - 一种通用的方法是对于TCP发送方无论何时到达一个新的确认，就将cwnd增加一个MSS（MSS/cwnd）字节。例如，如果MSS是1460字节并且cwnd是14600字节，则在一个RTT内发送10个报文段。每个到达ACK（假设每个报文段一个ACK）增加1/10MSS的拥塞窗口长度，因此在收到对所有10个报文段的确认后，拥塞窗口的值将增加了一个MSS
  - 何时应当结束拥塞避免避免的线性增长（每RTT 1MSS）
    - 出现超时时：与慢启动的情况一样，cwnd的值被设置为1个MSS，当丢包事件出现时，ssthresh的值被更新为cwnd的一半
    - 收到冗余ACK指示的丢包事件：TCP将cwnd的值减半（为使测量结果更好，计及已收到的3个冗余ACK要加上3个MSS），并且当收到3个冗余的ACK，将ssthresh的值记录为cwnd的值的一半
  - 结束拥塞避免后，进入快速恢复状态
- 快速恢复
  - 对于引起TCP进入快速恢复状态的缺失报文段，对收到的每个冗余ACK，cwnd的值增加一个MSS
  - 最终，当对丢失报文段的一个ACK到达时，TCP在降低cwnd后进入拥塞避免状态
  - 如果出现超时时间，快速恢复在执行如同在慢启动和拥塞避免中相同的动作后，迁移到慢启动状态：大概丢包事件出现时，cwnd的值被设置为1个MSS，并且ssthresh的值设置为cwnd值的一半

- 快速恢复是TCP推荐的而非必需的构件。有趣的是，一种称为TCP Tahoe的TCP早期版本，不管是发生超时指示的丢包事件，还是发生3个冗余ACK指示的丢包事件，都无条件地将拥塞窗口减至1个MSS，并进入慢启动阶段。TCP的较新版本TCP Reno，则综合了快速恢复

- TCP拥塞窗口演化的一个例子

  <img src="images/TCP拥塞窗口演化的一个例子.png" alt="image-20200218221628720" style="zoom:50%;" />

  - 在第8轮传输后出现3个冗余ACK。于是ssthresh的值被设置为6MSS。在TCP Reno下，拥塞窗口被设置为cwnd=9MSS，然后线性增长

- TCP拥塞控制：回顾

  - 忽略一条连接开始时初始的慢启动阶段，假定丢包由3个冗余的ACK而不是超时指示，TCP的拥塞控制是：每个RTT内cwnd线性（加性）增加1MSS，然后出现3个冗余ACK事件时cwnd减半（乘性减）。因此TCP拥塞控制常常被称为加性增、乘性减（Additive-Increase，Multiplicative-Decrease，AIMD）拥塞控制方式

  - AIMD拥塞控制引发了如图所示的“锯齿”行为，这也很好地图示了TCP检测带宽时的直觉

    <img src="images/加性增、乘性减的拥塞控制.png" alt="image-20200218230452899" style="zoom:50%;" />

- 对TCP吞吐量的宏观描述

  - 在这个分析中，我们将忽略在超时事件后出现的慢启动阶段（这些阶段通常非常短，因为发送方很快就以指数增长离开该阶段）

  - 在一个特定的往返间隔内，TCP发送数据的速率是拥塞窗口与当前RTT的函数。当窗口长度是w字节，且当前往返时间是RTT秒时，则TCP的发送速率大约时w/RTT。于是，TCP通过每经过1个RTT将增加1个MSS探测出额外的带宽，直到一个丢包事件发生

  - 当一个丢包事件发生时，用W表示w的值。假设在连接持续期间RTT和W几乎不变，那么TCP的传输速率在W/(2*RTT)到W/RTT之间变化

  - 这些假设导出了TCP稳态行为的一个高度简化的宏观描述。当速率增长至W/RTT时，网络丢弃来自连接的分组；然后发送速率就会减半，进而每过一个RTT就发送速率增加MSS/RTT，知道再次到达W/RTT为止。这一过程不断自我重复。因为TCP吞吐量（即速率）在两个极值之间线性增长，所以我们有：

    $$一条连接的平均吞吐量=\frac{0.75*W}{RTT}$$

- TODO

## 第4章 网络层

### 4.1 概述

#### 4.1.1 转发和路由选择

- 网络层功能
  - 转发
  - 路由选择
  - 连接建立：某些网络层体系结构如ATM、帧中继、MPLS，要求从源到目的地沿着所选择的路径彼此握手，以便在给定源到目的地连接中的网络层数据分组能够开始流动之前建立起状态。在网络层中，该过程被称为连接建立

#### 4.1.2 网络服务模型

- 网络服务模型定义了分组在发送与接收端系统之间的端到端运输特性
- 在发送主机中，当运输层向网络层传递一个分组时，能由网络层提供的特定服务包括：
  - 确保交付
  - 具有时延上届的确保交付

- 此外，能够为给定的源和目的地之间的分组流提供下列服务：
  - 有序分组交付
  - 确保最小带宽：这种网络层服务模仿在发送和接收主机之间的一条特定比特率的传输链路行为。只要发送主机以低于特定比特率的速率传输比特，则分组不会丢失，且每个分组会在预定的主机到主机时延内到达
  - 确保最大时延抖动：确保位于发送方的两个相继分组之间的时间量等于在目的地接收到它们之间的时间量（或这种间隔的变化不超过某些特定的值）
  - 安全性服务：除了机密性以外，网络层能够提供数据完整性和源鉴别服务

- 因特网的网络层提供了单一的服务，称为尽力而为服务（best-effort service）

- 因特网、ATM CBR和ATM ABR服务模型

  ![image-20200220215422231](images/因特网、ATM CBR和ATM ABR服务模型.png)

### 4.2 虚电路和数据报网络

- 虚电路（Virtual-Circuit，VC）网络：仅在网络层提供连接服务的计算机网络
- 数据报网络（datagram network）：仅在网络层提供无连接服务的计算机网络

#### 4.2.1 虚电路网络

- 一条虚电路的组成如下
  - 源和目的主机之间的路径（即一系列链路和路由器）
  - VC号，沿着该路径的每段链路的一个号码
  - 沿着该路径的每台路由器中的转发表表项

- TODO

#### 4.2.2 数据报网络

- 当分组从源到目的地传输，它通过一系列路由器传递。这些路由器中的每台都使用分组的目的地址来转发该分组

### 4.3 路由器工作原理

<img src="images/一个通用路由器系统结构的总体视图.png" alt="image-20200220224259164" style="zoom:50%;" />

- 一个通用路由器系统结构的总体视图
  - 输入端口
    - 将一条输入的物理链路与路由器相连接的物理层功能，这显示在上图输入端口部分最左侧的方框与输出端口部分最右侧的方框中
    - 它还要执行需要与位于入链路远端的数据链路层交互的数据链路层功能，这表示在输入与输出端口部分的中间方框中
    - 在输入端口还要完成查找功能，这显示在输入端口最右侧的方框中。正是在这里，通过查询转发表决定路由器的输出端口，到达的分组通过路由器的交换结构将转发到输出端口。控制分组（如携带路由选择协议信息的分组）从输入端口转发到路由选择处理器
  - 交换结构：交换结构将路由器的输入端口与输出端口相连接
  - 输出端口
    - 存储从交换结构接收的分组，并通过执行必要的链路层和物理层功能在输入链路上传输这些分组
  - 路由选择处理器
    - 执行路由选择协议。维护路由选择表以及连接的链路状态信息，并为路由器计算转发表
    - 还执行网络管理功能

- 路由器转发平面总是用硬件实现，以纳秒时间尺度运行；路由器控制平面通常用软件实现，在毫秒或秒时间尺度上运行

#### 4.3.1 输入端口

<img src="images/输入端口处理.png" alt="image-20200222150637241" style="zoom:50%;" />

- 转发表是路由选择处理器计算和更新的，但转发表的一份影子副本通常会被存放在每个输入端口。转发表从路由选择处理器经过独立总线复制到线路卡

- 在某些设计中，如果来自其他输入端口的分组当前正在使用该交换结构，一个分组可能会在进入交换结构时被暂时阻塞。因此，一个被阻塞的分组必需要在输入端口处排队，并等待稍后被及时调度以通过交换结构

- 输入端口处理除“查找”外必须采取采取许多其他动作
  - 必须出现物理层和链路层处理
  - 必须检查分组的版本、检验和以及寿命字段，并且重写后两个字段
  - 必须更新用于网络管理的计数器（如接收到的IP数据报的数目）

#### 4.3.2 交换结构

- 三种交换技术

  <img src="images/三种交换技术.png" alt="image-20200222151611342" style="zoom:50%;" />
  - 经内存交换：一个分组到达一个输入端口时，该端口会先通过中断方式向路由选择处理器发出信号。于是，该分组从输入端口处被复制到处理器内存中。路由选择处理器则从其首部中提取目的地址，在转发表中找出适当的输出端口，并将该分组复制到输出端口的缓存中
  - 经总线交换：输入端口经一根共享总线将分组直接传送到输出端口，不需要路由选择处理器的干预
  - 经互联网络交换

#### 4.3.3 输出端口

<img src="images/输出端口处理.png" alt="image-20200222152901057" style="zoom:50%;" />

#### 4.3.4 何时出现排队

- 在输入端口和输出端口处都能够形成分组队列
- 输出端口排队的后果就是，在输出端口的一个分组调度程序必须在这些排队的分组中选出一个来发送。这种选择可能是根据简单的原则来定，如先来先服务调度（FCFS），或者更复杂的调度规则，如加权公平排队（WFQ）。分组调度程序在提供服务质量保证（quality-of-service guarantee）方面起着关键作用

- 类似地，如果没有足够的内存来缓存一个入分组，那么必须作做出决定：要么丢弃到达的分组（弃尾策略），要么删除一个或多个已排队的分组来为新到的分组腾出空间。在某些情况下，在缓存填满前便丢弃（或在首部加标记）一个分组，以便向发送方提供一个拥塞信号的做法是有利的

- 如果交换结构不能快得（相对于输入线路速度而言）使所有到达的分组无时延地通过它传送，则在输入端口也将出现分组排队，因此到达的分组必需加入输入队列中，以等待通过交换结构传送到输出端口。这种现象叫做输入排队交换机中的线路前部（Head-Of-the-Line，HOL）阻塞，即在一个输入队列中排队的分组必须等待通过交换结构发送（即使输出端口是空闲的），因为它被位于线路前部的另一个分组所阻塞

### 4.4 网际协议：因特网中的转发和编制

- 因特网的网络层有三个主要组件
  - IP协议
  - 路由选择部分
  - 报告数据报中的差错和对某些网络层信息请求进行响应的设施，即互联网控制报文协议（ICMP）

- 因特网网络层的内部视图

  <img src="images/因特网网络层的内部视图.png" alt="image-20200222155951780" style="zoom:50%;" />

#### 4.4.1 数据报格式

- IPv4数据报格式

  <img src="images/IPv4数据报格式.png" alt="image-20200222160538498" style="zoom:50%;" />

  - 版本号：4位
  - 首部长度：4位
  - 服务类型：使不同类型的IP数据报（例如，一些特别要求低时延、高吞吐量或可靠性的数据报）能相互区别开来
  - 数据报长度：IP数据报的总长度（首部加上数据）。16位
  - 标识、标志、片偏移：这三个字段与IP分片有关
  - 寿命：Time-To-Live，TTL。用来确保数据报不会永远（如由于长时间的路由选择环路）在网络中循环。每当数据报由一台路由器处理时，该字段的值减1。若TTL字段减为0，则该数据报必须丢弃
  - 上层协议：该字段仅在一个IP数据报到达其最终目的地才会有用。该字段值指示了IP数据报的数据部分应交给哪个特定的运输层协议。例如，值为6表明数据部分要交给TCP，而值为17表明数据要交给UDP。协议号是将网络层与运输层绑定到一起的粘合剂，而端口号是将运输层和应用层绑定到一起的粘合剂
  - 首部检验和：首部检验和用于帮助路由器检测收到的IP数据报中的比特错误。注意到每台路由器上必须重新计算检验和并再次存放到原处，因为TTL字段以及可能的选项字段会改变
    - 为什么TCP/IP在运输层与网络层都执行差错检验：IP层只对IP首部计算了检验和，而TCP/UDP检验和是对整个TCP/UDP报文段进行的。其次，TCP/UDP与IP不一定都必须属于同一个协议栈，原则上TCP能运行在一个不同的协议（如ATM）上，而IP能够携带不一定要传递给TCP/UDP的数据
  - 源和目的IP地址
  - 选项
  - 数据（有效载荷）

- IP数据分片
  - 一个链路层帧能承载的最大数据量叫做最大传送单元（Maximum Transmission，MTU）
  - 对IP数据报长度具有严格限制并不是主要问题，问题在于发送方与目的方路径上的每段链路可能使用不同的链路层协议，且每种协议可能具有不同的MTU
  - 为坚持网络内核保持简单的原则，IPv4的设计者决定将数据报的重新组装工作放到端系统中，而不是放到网络路由器中
  - 当生成一个数据报时，发送主机在为该数据报设置源和目的地址的同时再贴上标识号。发送主机通常将为它发送的每个数据报的标识号加1。当某路由器需要对一个数据报分片时，形成的每个数据报（即片）具有初始数据报的源地址、目的地址与标识号。当目的地址从同一发送主机收到一系列数据报时，它能够检查数据报的标识号以确定哪些数据报实际上是同一较大数据报的片。由于IP是一种不可靠的服务，一个或多个片可能永远到达不了目的地。因为这种原因，为了让目的主机绝对相信它已收到了初始数据报的最后一个片，最后一个片的标志比特被设为0，而其他所有片的标志比特被设为1。另外，为了让目的主机确定是否丢失了一个片（且能按正确的顺序重新组装片），使用偏移字段指定该片应放在初始IP数据报的哪个位置
  - 在目的地，数据报的有效载荷仅当在IP层已完全重构为初始IP数据报时，才被传递给目的运输层。如果一个或多片没有到达目的地，则该不完整的数据报被丢弃且不会交给运输层。但是，若在运输层正使用着TCP，则TCP将通过让源以初始数据报来重传数据，以恢复这次丢包
  - 分片的开销
    - 首先，它使路由器和端系统更为复杂
    - 其次，分片能够被用于生成致命的Dos攻击，由此攻击者发送了一系列古怪的、无法预期的片

#### 4.4.2 IPv4编址

- 一个IP地址技术上是与一个接口相关联的，而不是与包括该接口的主机或路由器相关联的

- 在全球因特网中的每台主机和路由器上的每个接口，必须有一个全球唯一的IP地址（在NAT后面的接口除外）。然而，这些地址不能随意地自由选择。一个接口的IP地址的一部分需要由其连接的子网来决定

- 接口地址和子网

  <img src="images/接口地址和子网.png" alt="image-20200222165820970" style="zoom:50%;" />
  - 互联这3个主机接口与1个路由器接口的网络形成一个子网。IP编址为这个子网分配了一个地址：223.1.1.0/24，其中的/24记法，有时称为子网掩码

- 因特网的地址分配策略被称为无类别域间路由选择（Classless Interdomain Routing，CIDR）。CIDR将子网寻址的概念一般化了。因为对于子网寻址，32比特的IP地址被划分为两部分，并且也具有点分十进制形式a.b.c.d/x，其中x指示了地址的第一部分中的比特数
- 在CIDR被采用之前，IP地址的网络部分被限制为8、16或24比特，这是一种称为分类编址的编址方案，这是因为具有8、16和24比特子网地址的子网分别被称为A、B和C类网络。一个IP地址网络部分正好为1、2或3字节的要求，已经在支持数量迅速增加的具有小规模或中等规模子网的组织方面出现了问题

- 获取主机地址：动态主机配置协议

  - 动态主机配置协议（Dynamic Host Configuration，DHCP）允许主机自动获取（被分配）一个IP地址

  - 除了主机IP地址分配外，DHCP还允许一台主机得知其他信息，例如它的子网掩码、它的第一跳路由器地址（常称为默认网关）与它的本地DNS服务器地址

  - 由于DHCP具有能将主机连接进一个网络的网络相关方面的自动能力，故它又常被称为即插即用协议

  - HDCP是客户-服务器协议。在最简单场合下，每个子网将具有一台DHCP服务器。如果在某子网中没有服务器，则需要一个DHCP中继代理（通常是一台路由器），这个代理知道用于该网络的DHCP服务器的地址

  - DHCP协议是一个4个步骤的过程

    <img src="images/DHCP客户-服务器交互.png" alt="image-20200222202535894" style="zoom:50%;" />

    - DHCP服务器发现：使用一个DHCP发现报文来完成。客户在UDP分组中向端口67发送该发现报文。DHCP客户生成包含DHCP发现报文的IP数据报，其中使用广播目的地址255.255.255.255并且使用“本主机”源地址0.0.0.0。DHCP客户将该IP数据报传递给链路层，链路层然后将该帧广播到所有与该子网连接的子网
    - DHCP服务器提供：DHCP服务器收到一个DHCP发现报文，用一个DHCP提供报文向客户做出响应，仍然使用IP广播地址255.255.255.255。每台服务器提供的报文包含有收到的发现报文的事务ID、向客户推荐的IP地址、网络掩码以及IP地址租用期，即IP地址有效的时间量
    - DHCP请求：新到达的客户从一个或多个服务器中选择一个，并向选中的服务器提供一个DHCP请求报文进行响应，回显配置参数
    - DHCP ACK：服务器用DHCP ACK报文对DHCP请求报文进行响应，证实所要求的参数

  - 一旦客户收到DHCP ACK后，交互便完成了，并且该客户能够在租用期内使用DHCP分配的IP地址

- 网络地址转换（Network Address Translation，NAT）

  <img src="images/网络地址转换.png" alt="image-20200222211456156" style="zoom:50%;" />

  - 地址空间10.0.0.0/8是在RFC 1918中保留的3部分IP地址空间之一，这些地址用于家庭网络等专用网络或具有专用地址的地域。具有专用地址的地域是指其地址仅对该网络中的设备有意义的网络
  - NAT使能路由器对于外部世界来说甚至不像一台路由器。NAT路由器对外界的行为反过来就如同一个具有单一IP地址的单一设备。从本质上讲，NAT使能路由器对外界隐藏了家庭网络的细节
  - 使用NAT路由器上的一张NAT转换表（NAT translation table），并且在表项中包含了端口号及其IP地址

- UPnP
  - NAT穿越正越来越多地由通用即插即用（UPnP）提供，UPnP是一种允许主机发现并配置邻近NAT的协议。使用UPnP，在主机上运行的应用程序能够为某些请求的公共端口号请求一个NAT映射，该映射位于其（专用IP地址，专用端口号）和（公共IP地址，公共端口号）之间。如果NAT接受该请求并生成映射，则来自外部的结点能够发起到（公共IP地址，公共端口号）的TCP连接。此外，UPnP让该应用程序知道（公共IP地址，公共端口号），因此该应用程序能够向外部世界通告它
  - 总儿言之，UPnP允许外部主机使用TCP或UDP向NAT化的主机发起通信会话

#### 4.4.3 因特网控制报文协议

- ICMP通常被认为是IP的一部分，但从体系结构上讲它是位于IP之上的，因为ICMP报文是承载在IP分组中的

- ICMP报文有一个类型字段和一个编码字段，并且包含引起该ICMP报文首次生成的IP数据报的首部和前8字节内容（以便发送方能确定引发该差错的数据报）

- ICMP报文类型

  <img src="images/ICMP报文类型.png" alt="image-20200223135825363" style="zoom:50%;" />

#### 4.4.4 IPv6

- IPv6数据报格式

  <img src="images/IPv6数据报格式.png" alt="image-20200223140359406" style="zoom:50%;" />

  - 版本：4位
  - 流量类型：8位，该字段与IPv4中的服务类型（TOS）字段的含义相似
  - 流标签：20位，用于标识一条数据报的流
  - 有效载荷长度：16位
  - 下一个首部：该字段标识数据报中的内容（数据字段）需要交付给哪个协议。该字段使用与IPv4首部中协议字段相同的值
  - 跳限制
  - 源地址和目的地址
  - 数据

- IPv6中引入的最重要的变化显示在其数据报格式中

  - 扩大的地址容量：IPv6将IP地址长度从32比特增加到128比特。除了单播与多播地址 以外，IPv6还引入了一种称为任播地址的新型地址，这种地址可以使数据交付给一组主机中的任意一个
  - 简化高效的40字节首部
  - 流标签与优先级：该字段可用于给属于特殊流的分组加上标签，这些特殊流是发送方要求进行特殊处理的流，如一种非默认服务质量或需要实时服务的流

- 在IPv4数据报中出现的几个字段在IPv6已不复存在
  - 分片/重新组装：IPv6不允许在中间路由器上进行分片与组装。这种操作只能在源和目的地上进行。如果路由器收到的IPv6数据报因太大而不能转发到出链路上的话，则路由器只需丢掉该数据报，并向发送方发回一个“分组太大”的ICMP差错报文即可
  - 首部检验和：因为因特网层中的运输层和数据链路层协议执行了检验操作，IP设计者大概觉得在网络层中具有该项功能实属多余，可以将其去除
  - 选项：选项字段不再是标准IP首部的一部分了。但它没有消失，而是可能出现在IPv6首部中由“下一个首部”指出的位置上。这就是说，就像TCP或UDP协议首部能够是IP分组中的“下一个首部”，选项字段也能是“下一个首部”

- 从IPv4到IPv6的迁移
  - 双栈方法：使用该方法的IPv6结点还具有完整的IPv4实现，它有发送喝接收IPv4与IPv6两种数据报的能力
  - 建隧道：在隧道发送端的IPv6结点可将整个IPv6数据报放到一个IPv4数据报的数据字段中

#### 4.4.5 涉足IP安全性

- 安全网络层协议IPsec

### 4.5 路由选择算法

- 路由选择算法的一种广义分类方式是根据该算法是全局式的还是分散式的来加以区分
  - 全局式路由选择算法（global routing algorithm）：用完整的、全局性的网络知识计算出从源到目的地之间的最低费用路径。实践中，具有全局状态信息的算法常被称作链路状态（Link State，LS）算法，因为该算法必须知道网络中每条链路的费用
  - 分散式路由选择算法（decentralized routing algorithm）：以迭代、分布式的方式计算出最低费用路径。一个称为距离向量（Distance-Vector，DV）算法的分散式路由选择算法，之所以叫DV算法，是因为每个结点维护到网络中所有其他结点的费用（距离）估计的向量

- 根据算法是静态的还是动态的进行分类
  - 在静态路由选择算法中，随着时间的流逝，路由的变化是非常缓慢的，通常是人工干预进行调整
  - 动态路由选择算法能够当网络流量负载或拓扑发生变化时改变路由选择路径

- 根据它是负载敏感的还是负载迟钝的进行分类
  - 在负载敏感算法中，链路费用会动态地变化以反映出底层链路的当前拥塞水平
  - 当今的因特网路由选择算法（如RIP、OSPF和BGP）都是负载迟钝的，因为某条链路的费用不明显地反映其当前的拥塞水平

#### 4.5.1 链路状态路由选择算法

- 通过让每个结点向网络中所有其他结点广播链路状态分组，其中每个链路状态分组包含它所连接的链路的特征和费用。在实践中（如OSPF协议），这经常由链路状态广播算法来完成
- Dijkstra算法

#### 4.5.2 距离向量路由选择算法

- 分布式的：每个结点都要从一个或多个直接相连邻居接收某些信息，执行计算，然后将其计算结果发给邻居
- 迭代的：此过程一直要持续到邻居之间无更多信息要交换为止（有趣的是，此算法是自我终止的）
- 异步的：它不要去所有结点相互之间步伐一致地操作

- 在该分布式、异步算法中，每个结点不时地向它的每个邻居发送它的距离向量副本。当结点x从它的任何一个邻居v接收到一个新距离向量，它保存v的距离向量，然后使用Bellman-Ford方程更新它自己的距离向量

- TODO